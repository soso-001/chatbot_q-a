{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB6t+gKZXJTQYh9bcg5gP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soso-001/chatbot_q-a/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HrOzvZxiLtrE"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu tiktoken python-docx\n",
        "!pip install langchain-community\n",
        "!pip install tools\n",
        "!pip install -q PyMuPDF\n",
        "!pip install --upgrade huggingface_hub langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import requests\n",
        "import tempfile\n",
        "\n",
        "import fitz\n",
        "from docx import Document as DocxDocument\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.schema import Document\n",
        "\n",
        "from langchain.embeddings.base import Embeddings"
      ],
      "metadata": {
        "id": "t68NIiH5MaqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API key from environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAPI')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "MyTDw8tUMbpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "\n",
        "# Global QA chain\n",
        "qa_chain = None\n",
        "\n",
        "# üì¶ Global storage\n",
        "retriever = None\n",
        "\n",
        "def prepare_qa_chain(text):\n",
        "    global qa_chain\n",
        "    global retriever\n",
        "\n",
        "    # Step 1: Split document into chunks\n",
        "    docs = text_splitter.create_documents([text])\n",
        "\n",
        "    # Step 2: Create vector database\n",
        "    db = FAISS.from_documents(docs, embedding_model)\n",
        "    retriever = db.as_retriever()\n",
        "\n",
        "    # Step 3: Load LLM and create RetrievalQA chain\n",
        "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True\n",
        "    )"
      ],
      "metadata": {
        "id": "NEfwSpUakt8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÑ Extract text from local file\n",
        "def extract_text_from_file(file_path):\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "    if ext == \".txt\":\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    elif ext == \".pdf\":\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            # Explicitly load pages by index (correct order)\n",
        "            texts = []\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                text = page.get_text(\"text\")  # Use \"text\" for plain reading\n",
        "                texts.append(text)\n",
        "            return \"\\n\".join(texts)\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error reading PDF: {e}\"\n",
        "\n",
        "    elif ext == \".docx\":\n",
        "        doc = DocxDocument(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# üìÅ Handle local upload\n",
        "def handle_local_file(file):\n",
        "    try:\n",
        "        file_path = file.name\n",
        "        text = extract_text_from_file(file_path)\n",
        "        if not text:\n",
        "            return \"‚ùå Unsupported or empty file.\"\n",
        "        prepare_qa_chain(text)\n",
        "\n",
        "        return \"‚úÖ File loaded and RAG chain is ready.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "# üß† Create FAISS retriever\n",
        "def prepare_retriever(text):\n",
        "    global retriever\n",
        "    docs = text_splitter.create_documents([text])\n",
        "    db = FAISS.from_documents(docs, embedding_model)\n",
        "    retriever = db.as_retriever()\n",
        "    return \"‚úÖ Document processed and indexed.\"\n",
        "\n",
        "def answer_question(question):\n",
        "    global qa_chain\n",
        "    if not qa_chain:\n",
        "        return \"‚ö†Ô∏è Please load a document first.\"\n",
        "\n",
        "    try:\n",
        "        result = qa_chain({\"query\": question})\n",
        "        return result[\"result\"]\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error generating answer: {e}\"\n"
      ],
      "metadata": {
        "id": "xmnW-lLMMYxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üìö Document Q&A Chatbot with RAG + GPT-4\")\n",
        "    gr.Markdown(\"Choose a document source, load it, then ask questions!\")\n",
        "\n",
        "    source_choice = gr.Radio(\n",
        "        [\"üìÅ Local File\"],\n",
        "        label=\"Choose document\",\n",
        "        value=\"üìÅ Local File\",\n",
        "        interactive=True\n",
        "    )\n",
        "\n",
        "    local_file_input = gr.File(label=\"Upload a file (PDF, DOCX, TXT)\", file_types=[\".pdf\", \".txt\"], visible=True)\n",
        "    load_status = gr.Textbox(label=\"Load Status\", interactive=False)\n",
        "\n",
        "    question_box = gr.Textbox(label=\"Ask a question about the document\")\n",
        "    answer_box = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "\n",
        "\n",
        "    def toggle_inputs(choice):\n",
        "        return (\n",
        "            gr.update(visible=(choice == \"üìÅ Local File\")),\n",
        "        )\n",
        "\n",
        "    source_choice.change(\n",
        "        fn=toggle_inputs,\n",
        "        inputs=source_choice,\n",
        "        outputs=local_file_input\n",
        "    )\n",
        "\n",
        "    local_file_input.change(fn=handle_local_file, inputs=local_file_input, outputs=load_status)\n",
        "\n",
        "    question_box.submit(fn=answer_question, inputs=question_box, outputs=answer_box)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "yGFLDKWJLuSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdYtlT61Lubk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68Ell2ECLueW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-j81hLH4Lux4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avM3X6jXLu-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USWJ5cMWLvAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}